{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "fd7743960984479faccf535d089aa66a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_3a25ee2e7ede42348bfbe393f86b7645",
              "IPY_MODEL_69ef4d11676f4ee1b17d10f43f967cd8",
              "IPY_MODEL_1d184403f1ba43209e7d6b2f0cce07bd"
            ],
            "layout": "IPY_MODEL_813ce37f92094f2faac933a0cd20eff2"
          }
        },
        "3a25ee2e7ede42348bfbe393f86b7645": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_392e780fab9f4dc1a547858576dc913c",
            "placeholder": "​",
            "style": "IPY_MODEL_e8070c3aeeb34f74b910deda7fc243cd",
            "value": "Map: 100%"
          }
        },
        "69ef4d11676f4ee1b17d10f43f967cd8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_10794b544656496eb39367eaf8d1bccf",
            "max": 14732,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_abf2a5e215eb4344a83cb3e9f14e333b",
            "value": 14732
          }
        },
        "1d184403f1ba43209e7d6b2f0cce07bd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_010eee3a02b94c46ae99c87bdd79ce0c",
            "placeholder": "​",
            "style": "IPY_MODEL_789b4154ccea4d10ac2c3877c8175823",
            "value": " 14732/14732 [00:38&lt;00:00, 434.65 examples/s]"
          }
        },
        "813ce37f92094f2faac933a0cd20eff2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "392e780fab9f4dc1a547858576dc913c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e8070c3aeeb34f74b910deda7fc243cd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "10794b544656496eb39367eaf8d1bccf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "abf2a5e215eb4344a83cb3e9f14e333b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "010eee3a02b94c46ae99c87bdd79ce0c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "789b4154ccea4d10ac2c3877c8175823": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "50a47afcbcc14968b638cdeb31a1d33f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ff294332a5e947b69af3e478f2cee53a",
              "IPY_MODEL_47902c11bf744db1995d1718b7b6e26f",
              "IPY_MODEL_44a6b0a21d934083923fa2f48c3d9b21"
            ],
            "layout": "IPY_MODEL_b1a44559e8d241fd829182ee1852ba1c"
          }
        },
        "ff294332a5e947b69af3e478f2cee53a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9353215ad1d2432ab2326a7ea7ac9133",
            "placeholder": "​",
            "style": "IPY_MODEL_7070b896092b463c95675decddb5a5c7",
            "value": "Map: 100%"
          }
        },
        "47902c11bf744db1995d1718b7b6e26f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ac7c3124e342472fbf5629ffc2654a81",
            "max": 818,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_913373e1280b4a138e5c0c93cf5f2371",
            "value": 818
          }
        },
        "44a6b0a21d934083923fa2f48c3d9b21": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d4bb4dcc96ee4b4ea4451877cf3720eb",
            "placeholder": "​",
            "style": "IPY_MODEL_3cc66b1955074ae0a58ce0937beea354",
            "value": " 818/818 [00:01&lt;00:00, 570.73 examples/s]"
          }
        },
        "b1a44559e8d241fd829182ee1852ba1c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9353215ad1d2432ab2326a7ea7ac9133": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7070b896092b463c95675decddb5a5c7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ac7c3124e342472fbf5629ffc2654a81": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "913373e1280b4a138e5c0c93cf5f2371": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d4bb4dcc96ee4b4ea4451877cf3720eb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3cc66b1955074ae0a58ce0937beea354": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a5da4991f48141eea65ae2aa9da414b6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_9fd0fcc8fdd74f0bb82c6c6326cf2d0c",
              "IPY_MODEL_260f9e44afd54974b8af22edc87d1e63",
              "IPY_MODEL_8a2a923408d5457a8aafff535f206908"
            ],
            "layout": "IPY_MODEL_9c010483929b4dec9e42739422f7b425"
          }
        },
        "9fd0fcc8fdd74f0bb82c6c6326cf2d0c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c07123e79cd1410a84eeb2b4e19997ee",
            "placeholder": "​",
            "style": "IPY_MODEL_1a9d51284f3e4eaebe06051a299a5f61",
            "value": "Map: 100%"
          }
        },
        "260f9e44afd54974b8af22edc87d1e63": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8cb530190bc94492b324341cbcac18f0",
            "max": 819,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f7524c2bb8694f02943ad6d0b51b9dd4",
            "value": 819
          }
        },
        "8a2a923408d5457a8aafff535f206908": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_173ee572b7c346cb8846d07b208c3697",
            "placeholder": "​",
            "style": "IPY_MODEL_df7a76faca114aa8b5e90eaf2a481c14",
            "value": " 819/819 [00:01&lt;00:00, 599.88 examples/s]"
          }
        },
        "9c010483929b4dec9e42739422f7b425": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c07123e79cd1410a84eeb2b4e19997ee": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1a9d51284f3e4eaebe06051a299a5f61": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8cb530190bc94492b324341cbcac18f0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f7524c2bb8694f02943ad6d0b51b9dd4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "173ee572b7c346cb8846d07b208c3697": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "df7a76faca114aa8b5e90eaf2a481c14": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "da200b20ce9e493296b4f22ec8f9c303": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c2feb1e0b0604df0bf9f3c9f791584ec",
              "IPY_MODEL_288196b8c6dd44769bb867f97a2a9f7b",
              "IPY_MODEL_f3d20102d68747a398e8f2dc720e04a0"
            ],
            "layout": "IPY_MODEL_8db221c3c4f7433ea69dd1ed8406e3b1"
          }
        },
        "c2feb1e0b0604df0bf9f3c9f791584ec": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c7bc254e2d744696b9e9102fbfe686a3",
            "placeholder": "​",
            "style": "IPY_MODEL_8ad616882e9b44b6b841bb7ab3627965",
            "value": "model.safetensors: 100%"
          }
        },
        "288196b8c6dd44769bb867f97a2a9f7b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_034235901a93456c92afe95ed07332ff",
            "max": 557709915,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_78d9b3b363b04ec68ce929431ca0b82e",
            "value": 557709915
          }
        },
        "f3d20102d68747a398e8f2dc720e04a0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_be389c1a9adf453b8d124749084015cd",
            "placeholder": "​",
            "style": "IPY_MODEL_4f70040e240b450e8da83afca9d8e71b",
            "value": " 558M/558M [00:15&lt;00:00, 85.1MB/s]"
          }
        },
        "8db221c3c4f7433ea69dd1ed8406e3b1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c7bc254e2d744696b9e9102fbfe686a3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8ad616882e9b44b6b841bb7ab3627965": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "034235901a93456c92afe95ed07332ff": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "78d9b3b363b04ec68ce929431ca0b82e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "be389c1a9adf453b8d124749084015cd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4f70040e240b450e8da83afca9d8e71b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "095aab3d704a44778b9366857a787c9c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_813d080a411a46f6981c088966350bf0",
              "IPY_MODEL_c9e1c3fc0c304a518ed9a7a2be002c31",
              "IPY_MODEL_1b8a32dd852c4d7eb38ebfb0d2ec4135"
            ],
            "layout": "IPY_MODEL_dd6d94566a804e75833bb8b6d8520d36"
          }
        },
        "813d080a411a46f6981c088966350bf0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cca7eb8e1c424dc9b3f6e354ba89e011",
            "placeholder": "​",
            "style": "IPY_MODEL_f5d28b2d15db429a80356a10e8a94b30",
            "value": "Downloading builder script: "
          }
        },
        "c9e1c3fc0c304a518ed9a7a2be002c31": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_10dd7c3df5f54b2591f65656d537fc7a",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_40c1806578ee41cda8ee7b33eea7cbf1",
            "value": 1
          }
        },
        "1b8a32dd852c4d7eb38ebfb0d2ec4135": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4a6b0251deb849759903944cacfbbd7c",
            "placeholder": "​",
            "style": "IPY_MODEL_73b6b17c7c6947ea8716829dd3162e07",
            "value": " 6.27k/? [00:00&lt;00:00, 87.6kB/s]"
          }
        },
        "dd6d94566a804e75833bb8b6d8520d36": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cca7eb8e1c424dc9b3f6e354ba89e011": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f5d28b2d15db429a80356a10e8a94b30": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "10dd7c3df5f54b2591f65656d537fc7a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "40c1806578ee41cda8ee7b33eea7cbf1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "4a6b0251deb849759903944cacfbbd7c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "73b6b17c7c6947ea8716829dd3162e07": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R8lf4-J8U9dx"
      },
      "outputs": [],
      "source": [
        "!pip install -q transformers datasets rouge_score accelerate sentencepiece\n",
        "import torch, pandas as pd\n",
        "from zipfile import ZipFile\n",
        "from datasets import load_dataset, Dataset\n",
        "from transformers import (\n",
        "    AutoTokenizer, AutoModelForSeq2SeqLM,\n",
        "    Seq2SeqTrainer, Seq2SeqTrainingArguments, DataCollatorForSeq2Seq\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ZipFile(\"/content/drive/MyDrive/data.zip\").extractall(\"/content/data\")"
      ],
      "metadata": {
        "id": "F925jwMBVNT6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Load & Inspect Data\n",
        "train_df = pd.read_csv(\"/content/data/samsum-train.csv\")\n",
        "val_df   = pd.read_csv(\"/content/data/samsum-validation.csv\")\n",
        "test_df  = pd.read_csv(\"/content/data/samsum-test.csv\")\n",
        "\n",
        "print(\"Train shape:\", train_df.shape)\n",
        "print(train_df.head(2))"
      ],
      "metadata": {
        "id": "3lLpsMFuW_KQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e6ebc8f8-7641-434d-e46d-0b62256ac9b0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train shape: (14732, 3)\n",
            "         id                                           dialogue  \\\n",
            "0  13818513  Amanda: I baked  cookies. Do you want some?\\r\\...   \n",
            "1  13728867  Olivia: Who are you voting for in this electio...   \n",
            "\n",
            "                                             summary  \n",
            "0  Amanda baked cookies and will bring Jerry some...  \n",
            "1  Olivia and Olivier are voting for liberals in ...  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Convert to Hugging Face Dataset\n",
        "train_ds = Dataset.from_pandas(train_df)\n",
        "val_ds   = Dataset.from_pandas(val_df)\n",
        "test_ds  = Dataset.from_pandas(test_df)"
      ],
      "metadata": {
        "id": "75FnZWPgXCsP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**change to SLM here**"
      ],
      "metadata": {
        "id": "KNEpte7XSwB2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Tokenization & Preprocessing\n",
        "from transformers import AutoTokenizer\n",
        "model_name = \"facebook/bart-base\"   # you can use bart-large-cnn or t5-base. #chnage here to t-small for change it into SLM , trading power for efficiency\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "\n",
        "def preprocess(batch):\n",
        "    inputs = []\n",
        "    labels = []\n",
        "    for dialogue, summary in zip(batch[\"dialogue\"], batch[\"summary\"]):\n",
        "        if isinstance(dialogue, str) and isinstance(summary, str):\n",
        "            inputs.append(tokenizer(text=dialogue, truncation=True, max_length=512)[\"input_ids\"])\n",
        "            labels.append(tokenizer(text_target=summary, truncation=True, max_length=128)[\"input_ids\"])\n",
        "        else:\n",
        "            # Handle cases where dialogue or summary are not strings, e.g., skip or log a warning\n",
        "            print(f\"Skipping example due to invalid data types: dialogue type = {type(dialogue)}, summary type = {type(summary)}\")\n",
        "            continue # Skip this example\n",
        "\n",
        "    return {\"input_ids\": inputs, \"labels\": labels}\n",
        "\n",
        "\n",
        "train_tokenized = train_ds.map(preprocess, batched=True, remove_columns=train_ds.column_names)\n",
        "val_tokenized   = val_ds.map(preprocess, batched=True, remove_columns=val_ds.column_names)\n",
        "test_tokenized  = test_ds.map(preprocess, batched=True, remove_columns=test_ds.column_names)\n",
        "\n",
        "train_tokenized.set_format(type=\"torch\", columns=[\"input_ids\", \"labels\"])\n",
        "val_tokenized.set_format(type=\"torch\", columns=[\"input_ids\", \"labels\"])\n",
        "test_tokenized.set_format(type=\"torch\", columns=[\"input_ids\", \"labels\"])"
      ],
      "metadata": {
        "id": "QOM1VSlyYdej",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 131,
          "referenced_widgets": [
            "fd7743960984479faccf535d089aa66a",
            "3a25ee2e7ede42348bfbe393f86b7645",
            "69ef4d11676f4ee1b17d10f43f967cd8",
            "1d184403f1ba43209e7d6b2f0cce07bd",
            "813ce37f92094f2faac933a0cd20eff2",
            "392e780fab9f4dc1a547858576dc913c",
            "e8070c3aeeb34f74b910deda7fc243cd",
            "10794b544656496eb39367eaf8d1bccf",
            "abf2a5e215eb4344a83cb3e9f14e333b",
            "010eee3a02b94c46ae99c87bdd79ce0c",
            "789b4154ccea4d10ac2c3877c8175823",
            "50a47afcbcc14968b638cdeb31a1d33f",
            "ff294332a5e947b69af3e478f2cee53a",
            "47902c11bf744db1995d1718b7b6e26f",
            "44a6b0a21d934083923fa2f48c3d9b21",
            "b1a44559e8d241fd829182ee1852ba1c",
            "9353215ad1d2432ab2326a7ea7ac9133",
            "7070b896092b463c95675decddb5a5c7",
            "ac7c3124e342472fbf5629ffc2654a81",
            "913373e1280b4a138e5c0c93cf5f2371",
            "d4bb4dcc96ee4b4ea4451877cf3720eb",
            "3cc66b1955074ae0a58ce0937beea354",
            "a5da4991f48141eea65ae2aa9da414b6",
            "9fd0fcc8fdd74f0bb82c6c6326cf2d0c",
            "260f9e44afd54974b8af22edc87d1e63",
            "8a2a923408d5457a8aafff535f206908",
            "9c010483929b4dec9e42739422f7b425",
            "c07123e79cd1410a84eeb2b4e19997ee",
            "1a9d51284f3e4eaebe06051a299a5f61",
            "8cb530190bc94492b324341cbcac18f0",
            "f7524c2bb8694f02943ad6d0b51b9dd4",
            "173ee572b7c346cb8846d07b208c3697",
            "df7a76faca114aa8b5e90eaf2a481c14"
          ]
        },
        "outputId": "f278e642-5851-4cc9-b132-cf059faa913f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/14732 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "fd7743960984479faccf535d089aa66a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Skipping example due to invalid data types: dialogue type = <class 'NoneType'>, summary type = <class 'str'>\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/818 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "50a47afcbcc14968b638cdeb31a1d33f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/819 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a5da4991f48141eea65ae2aa9da414b6"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Device & Training Config\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(\"Device:\", device)"
      ],
      "metadata": {
        "id": "Iop6mPG2kaWF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2929ec4c-c89d-481a-98d0-52af11340bd5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Device: cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Supervised Fine-tuning (Baseline)\n",
        "from transformers import AutoModelForSeq2SeqLM, Seq2SeqTrainer, Seq2SeqTrainingArguments, DataCollatorForSeq2Seq\n",
        "import torch\n",
        "\n",
        "# Define training parameters\n",
        "batch_size = 4\n",
        "num_epochs = 5\n",
        "fp16 = torch.cuda.is_available()\n",
        "model_name = \"facebook/a\"\n",
        "\n",
        "model = AutoModelForSeq2SeqLM.from_pretrained(model_name)\n",
        "\n",
        "data_collator = DataCollatorForSeq2Seq(tokenizer=tokenizer, model=model)\n",
        "\n",
        "args = Seq2SeqTrainingArguments(\n",
        "    output_dir=\"/content/drive/MyDrive/rl_project/baseline\",\n",
        "    eval_strategy=\"epoch\",\n",
        "    learning_rate=3e-5,\n",
        "    per_device_train_batch_size=batch_size,\n",
        "    per_device_eval_batch_size=batch_size,\n",
        "    num_train_epochs=num_epochs,\n",
        "    weight_decay=0.01,\n",
        "    predict_with_generate=True,\n",
        "    fp16=fp16,\n",
        "    logging_dir=\"/content/drive/MyDrive/rl_project/logs\",\n",
        "    save_total_limit=2,\n",
        "    save_strategy=\"epoch\",\n",
        "    logging_strategy=\"steps\",\n",
        "    logging_steps=100,\n",
        "    report_to=\"none\"\n",
        ")\n",
        "\n",
        "trainer = Seq2SeqTrainer(\n",
        "    model=model,\n",
        "    args=args,\n",
        "    train_dataset=train_tokenized,\n",
        "    eval_dataset=val_tokenized,\n",
        "    tokenizer=tokenizer,\n",
        "    data_collator=data_collator # Add data collator here\n",
        ")\n",
        "trainer.train()\n",
        "model.save_pretrained(\"/content/drive/MyDrive/rl_project/baseline_model\")\n",
        "tokenizer.save_pretrained(\"/content/drive/MyDrive/rl_project/baseline_model\")"
      ],
      "metadata": {
        "id": "2YZSlkZaYpKy",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 436,
          "referenced_widgets": [
            "da200b20ce9e493296b4f22ec8f9c303",
            "c2feb1e0b0604df0bf9f3c9f791584ec",
            "288196b8c6dd44769bb867f97a2a9f7b",
            "f3d20102d68747a398e8f2dc720e04a0",
            "8db221c3c4f7433ea69dd1ed8406e3b1",
            "c7bc254e2d744696b9e9102fbfe686a3",
            "8ad616882e9b44b6b841bb7ab3627965",
            "034235901a93456c92afe95ed07332ff",
            "78d9b3b363b04ec68ce929431ca0b82e",
            "be389c1a9adf453b8d124749084015cd",
            "4f70040e240b450e8da83afca9d8e71b"
          ]
        },
        "outputId": "a0f3e4a5-af50-4b9f-a4d8-7de5b32eeed8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/558M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "da200b20ce9e493296b4f22ec8f9c303"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-3582275274.py:33: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Seq2SeqTrainer.__init__`. Use `processing_class` instead.\n",
            "  trainer = Seq2SeqTrainer(\n",
            "/usr/local/lib/python3.12/dist-packages/transformers/data/data_collator.py:741: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at /pytorch/torch/csrc/utils/tensor_new.cpp:253.)\n",
            "  batch[\"labels\"] = torch.tensor(batch[\"labels\"], dtype=torch.int64)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='11049' max='11049' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [11049/11049 20:49, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>1.800600</td>\n",
              "      <td>1.552432</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>1.540500</td>\n",
              "      <td>1.491329</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>1.269900</td>\n",
              "      <td>1.485864</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/transformers/modeling_utils.py:4037: UserWarning: Moving the following attributes in the config to the generation config: {'early_stopping': True, 'num_beams': 4, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0}. You are seeing this warning because you've set generation parameters in the model config, as opposed to in the generation config.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('/content/drive/MyDrive/rl_project/baseline_model/tokenizer_config.json',\n",
              " '/content/drive/MyDrive/rl_project/baseline_model/special_tokens_map.json',\n",
              " '/content/drive/MyDrive/rl_project/baseline_model/vocab.json',\n",
              " '/content/drive/MyDrive/rl_project/baseline_model/merges.txt',\n",
              " '/content/drive/MyDrive/rl_project/baseline_model/added_tokens.json',\n",
              " '/content/drive/MyDrive/rl_project/baseline_model/tokenizer.json')"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1107a60d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8eb1c2d3-21a6-47c9-f33b-71d121ac114c"
      },
      "source": [
        "!pip install evaluate"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting evaluate\n",
            "  Downloading evaluate-0.4.6-py3-none-any.whl.metadata (9.5 kB)\n",
            "Requirement already satisfied: datasets>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from evaluate) (4.0.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from evaluate) (2.0.2)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.12/dist-packages (from evaluate) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (from evaluate) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.12/dist-packages (from evaluate) (2.32.4)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.12/dist-packages (from evaluate) (4.67.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.12/dist-packages (from evaluate) (3.5.0)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.12/dist-packages (from evaluate) (0.70.16)\n",
            "Requirement already satisfied: fsspec>=2021.05.0 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]>=2021.05.0->evaluate) (2025.3.0)\n",
            "Requirement already satisfied: huggingface-hub>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from evaluate) (0.35.3)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from evaluate) (25.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from datasets>=2.0.0->evaluate) (3.19.1)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.12/dist-packages (from datasets>=2.0.0->evaluate) (18.1.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from datasets>=2.0.0->evaluate) (6.0.3)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]>=2021.05.0->evaluate) (3.12.15)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.7.0->evaluate) (4.15.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.7.0->evaluate) (1.1.10)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.19.0->evaluate) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.19.0->evaluate) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.19.0->evaluate) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.19.0->evaluate) (2025.8.3)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas->evaluate) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas->evaluate) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas->evaluate) (2025.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (1.7.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (6.6.4)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (0.3.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (1.20.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas->evaluate) (1.17.0)\n",
            "Downloading evaluate-0.4.6-py3-none-any.whl (84 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.1/84.1 kB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: evaluate\n",
            "Successfully installed evaluate-0.4.6\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from evaluate import load\n",
        "import torch\n",
        "rouge = load(\"rouge\")\n",
        "\n",
        "def evaluate(dataset, name=\"Baseline\", max_samples=200):\n",
        "    preds, refs = [], []\n",
        "\n",
        "    # Use a smaller subset for speed if needed\n",
        "    # Ensure max_samples does not exceed dataset size\n",
        "    num_samples = min(max_samples, len(dataset))\n",
        "    for example in dataset.select(range(num_samples)):\n",
        "        # Tokenize and move inputs to the model's device\n",
        "        inputs = tokenizer(\n",
        "            example[\"dialogue\"],\n",
        "            return_tensors=\"pt\",\n",
        "            truncation=True,\n",
        "            max_length=512\n",
        "        ).to(model.device)\n",
        "\n",
        "        # Generate summary (disable gradients for speed)\n",
        "        with torch.no_grad():\n",
        "            ids = model.generate(\n",
        "                **inputs,\n",
        "                max_length=128,\n",
        "                num_beams=4,  # optional: improves quality\n",
        "                early_stopping=True\n",
        "            )\n",
        "\n",
        "        # Decode predictions\n",
        "        pred = tokenizer.decode(ids[0], skip_special_tokens=True)\n",
        "        preds.append(pred)\n",
        "        refs.append(example[\"summary\"])\n",
        "\n",
        "    # Compute ROUGE scores\n",
        "    result = rouge.compute(predictions=preds, references=refs, use_stemmer=True)\n",
        "    # Access the ROUGE-L F1 score directly\n",
        "    print(f\"\\n{name} ROUGE-L F1:\", result[\"rougeL\"])\n",
        "    return result\n",
        "\n",
        "# Evaluate on a small subset of the test set\n",
        "baseline_scores = evaluate(test_ds)"
      ],
      "metadata": {
        "id": "wPY6haXMr5VX",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85,
          "referenced_widgets": [
            "095aab3d704a44778b9366857a787c9c",
            "813d080a411a46f6981c088966350bf0",
            "c9e1c3fc0c304a518ed9a7a2be002c31",
            "1b8a32dd852c4d7eb38ebfb0d2ec4135",
            "dd6d94566a804e75833bb8b6d8520d36",
            "cca7eb8e1c424dc9b3f6e354ba89e011",
            "f5d28b2d15db429a80356a10e8a94b30",
            "10dd7c3df5f54b2591f65656d537fc7a",
            "40c1806578ee41cda8ee7b33eea7cbf1",
            "4a6b0251deb849759903944cacfbbd7c",
            "73b6b17c7c6947ea8716829dd3162e07"
          ]
        },
        "outputId": "8113f59d-ceec-441f-9fdf-432e526924e3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading builder script: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "095aab3d704a44778b9366857a787c9c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Baseline ROUGE-L F1: 0.4267814580861652\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#RL Fine-tuning\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torch.optim import Adam\n",
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "from evaluate import load"
      ],
      "metadata": {
        "id": "ieHrWQwFvSC3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "wNuJJ1a9w2yo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load ROUGE metric\n",
        "rouge = load(\"rouge\")\n",
        "\n",
        "# Load baseline model locally\n",
        "model_rl = AutoModelForSeq2SeqLM.from_pretrained(\"/content/drive/MyDrive/rl_project/baseline_model\").to(\"cuda\")\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"/content/drive/MyDrive/rl_project/baseline_model\")"
      ],
      "metadata": {
        "id": "drQwNlb_whzo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = Adam(model_rl.parameters(), lr=5e-6)"
      ],
      "metadata": {
        "id": "reS5tY0lwnEe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Reward function\n",
        "def compute_rougeL(ref, pred):\n",
        "    return rouge.compute(predictions=[pred], references=[ref], use_stemmer=True)[\"rougeL\"]"
      ],
      "metadata": {
        "id": "uGtulKk-wpeP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Single RL step\n",
        "def train_rl_step(batch_dialogues, batch_refs):\n",
        "    inputs = tokenizer(\n",
        "        batch_dialogues, return_tensors=\"pt\",\n",
        "        padding=True, truncation=True, max_length=512\n",
        "    ).to(\"cuda\")\n",
        "\n",
        "    # Greedy baseline\n",
        "    with torch.no_grad():\n",
        "        greedy_ids = model_rl.generate(**inputs, max_length=128)\n",
        "    greedy_txt = tokenizer.batch_decode(greedy_ids, skip_special_tokens=True)\n",
        "\n",
        "    # Sampled output\n",
        "    sampled_ids = model_rl.generate(\n",
        "        **inputs, do_sample=True, top_k=50, top_p=0.95, max_length=128\n",
        "    )\n",
        "    sampled_txt = tokenizer.batch_decode(sampled_ids, skip_special_tokens=True)\n",
        "\n",
        "    # Compute advantages\n",
        "    r_sampled = [compute_rougeL(r, s) for r, s in zip(batch_refs, sampled_txt)]\n",
        "    r_greedy  = [compute_rougeL(r, g) for r, g in zip(batch_refs, greedy_txt)]\n",
        "    adv = torch.tensor(np.array(r_sampled) - np.array(r_greedy), dtype=torch.float, device=\"cuda\")\n",
        "\n",
        "    # Compute log-prob loss\n",
        "    labels = sampled_ids.clone()\n",
        "    outputs = model_rl(**inputs, labels=labels)\n",
        "    log_probs = -outputs.loss\n",
        "    loss = -(adv * log_probs).mean()\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    torch.nn.utils.clip_grad_norm_(model_rl.parameters(), 1.0)\n",
        "    optimizer.step()\n",
        "    return loss.item()\n"
      ],
      "metadata": {
        "id": "pt96j-W0wsX6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# RL Training Loop (demo)\n",
        "num_epochs = 1      # demo loop\n",
        "num_batches = 50    # small number for quick run\n",
        "batch_size = 4\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    total_loss = 0\n",
        "    for _ in tqdm(range(num_batches)):\n",
        "        batch = train_df.sample(batch_size)\n",
        "        loss = train_rl_step(batch[\"dialogue\"].tolist(), batch[\"summary\"].tolist())\n",
        "        total_loss += loss\n",
        "    print(f\"Epoch {epoch+1} RL loss:\", total_loss / num_batches)"
      ],
      "metadata": {
        "id": "sIZmuHyBw2L8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "82152ab7-bcac-42b0-f346-3e5ff66b6691"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 50/50 [02:48<00:00,  3.37s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1 RL loss: 0.06552471210248768\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_rl.save_pretrained(\"/content/drive/MyDrive/rl_project/rl_model\")\n",
        "tokenizer.save_pretrained(\"/content/drive/MyDrive/rl_project/rl_model\")\n",
        "print(\"✅ RL model saved locally at /content/drive/MyDrive/rl_project/rl_model\")"
      ],
      "metadata": {
        "id": "LXitu-FPw3P2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8f0f9ae0-5df5-47f2-b977-7a3ec426eea3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ RL model saved locally at /content/drive/MyDrive/rl_project/rl_model\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load RL model\n",
        "model_rl = AutoModelForSeq2SeqLM.from_pretrained(\"/content/drive/MyDrive/rl_project/rl_model\").to(\"cuda\")\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"/content/drive/MyDrive/rl_project/rl_model\")\n",
        "\n",
        "# Reuse your evaluate() function\n",
        "rl_scores = evaluate(test_ds, name=\"RL\")"
      ],
      "metadata": {
        "id": "XlAlBn0EzdsC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "abefd5b6-8ec4-4e76-9334-b7dd87b91a53"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "RL ROUGE-L F1: 0.4267814580861652\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(5):\n",
        "    dialogue = test_df.iloc[i][\"dialogue\"]\n",
        "    reference = test_df.iloc[i][\"summary\"]\n",
        "\n",
        "    inputs = tokenizer(dialogue, return_tensors=\"pt\", truncation=True, max_length=512).to(\"cuda\")\n",
        "    summary_ids = model_rl.generate(**inputs, max_length=128, num_beams=4)\n",
        "    pred_summary = tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
        "\n",
        "    print(f\"Dialogue #{i+1}:\\n{dialogue}\\n\")\n",
        "    print(f\"Reference Summary:\\n{reference}\\n\")\n",
        "    print(f\"RL Model Summary:\\n{pred_summary}\\n\")\n",
        "    print(\"-\" * 80)\n"
      ],
      "metadata": {
        "id": "hymV4eL5zhQq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "78d97ead-af65-4cc0-f562-aefb83b14d4c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dialogue #1:\n",
            "Hannah: Hey, do you have Betty's number?\n",
            "Amanda: Lemme check\n",
            "Hannah: <file_gif>\n",
            "Amanda: Sorry, can't find it.\n",
            "Amanda: Ask Larry\n",
            "Amanda: He called her last time we were at the park together\n",
            "Hannah: I don't know him well\n",
            "Hannah: <file_gif>\n",
            "Amanda: Don't be shy, he's very nice\n",
            "Hannah: If you say so..\n",
            "Hannah: I'd rather you texted him\n",
            "Amanda: Just text him 🙂\n",
            "Hannah: Urgh.. Alright\n",
            "Hannah: Bye\n",
            "Amanda: Bye bye\n",
            "\n",
            "Reference Summary:\n",
            "Hannah needs Betty's number but Amanda doesn't have it. She needs to contact Larry.\n",
            "\n",
            "RL Model Summary:\n",
            "Amanda can't find Betty's number. Larry called her last time they were at the park together.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "Dialogue #2:\n",
            "Eric: MACHINE!\n",
            "Rob: That's so gr8!\n",
            "Eric: I know! And shows how Americans see Russian ;)\n",
            "Rob: And it's really funny!\n",
            "Eric: I know! I especially like the train part!\n",
            "Rob: Hahaha! No one talks to the machine like that!\n",
            "Eric: Is this his only stand-up?\n",
            "Rob: Idk. I'll check.\n",
            "Eric: Sure.\n",
            "Rob: Turns out no! There are some of his stand-ups on youtube.\n",
            "Eric: Gr8! I'll watch them now!\n",
            "Rob: Me too!\n",
            "Eric: MACHINE!\n",
            "Rob: MACHINE!\n",
            "Eric: TTYL?\n",
            "Rob: Sure :)\n",
            "\n",
            "Reference Summary:\n",
            "Eric and Rob are going to watch a stand-up on youtube.\n",
            "\n",
            "RL Model Summary:\n",
            "Eric and Rob like Rob's stand-up. Rob will watch it now.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "Dialogue #3:\n",
            "Lenny: Babe, can you help me with something?\n",
            "Bob: Sure, what's up?\n",
            "Lenny: Which one should I pick?\n",
            "Bob: Send me photos\n",
            "Lenny:  <file_photo>\n",
            "Lenny:  <file_photo>\n",
            "Lenny:  <file_photo>\n",
            "Bob: I like the first ones best\n",
            "Lenny: But I already have purple trousers. Does it make sense to have two pairs?\n",
            "Bob: I have four black pairs :D :D\n",
            "Lenny: yeah, but shouldn't I pick a different color?\n",
            "Bob: what matters is what you'll give you the most outfit options\n",
            "Lenny: So I guess I'll buy the first or the third pair then\n",
            "Bob: Pick the best quality then\n",
            "Lenny: ur right, thx\n",
            "Bob: no prob :)\n",
            "\n",
            "Reference Summary:\n",
            "Lenny can't decide which trousers to buy. Bob advised Lenny on that topic. Lenny goes with Bob's advice to pick the trousers that are of best quality.\n",
            "\n",
            "RL Model Summary:\n",
            "Lenny will buy the first pair of purple trousers. Bob has four black pairs.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "Dialogue #4:\n",
            "Will: hey babe, what do you want for dinner tonight?\n",
            "Emma:  gah, don't even worry about it tonight\n",
            "Will: what do you mean? everything ok?\n",
            "Emma: not really, but it's ok, don't worry about cooking though, I'm not hungry\n",
            "Will: Well what time will you be home?\n",
            "Emma: soon, hopefully\n",
            "Will: you sure? Maybe you want me to pick you up?\n",
            "Emma: no no it's alright. I'll be home soon, i'll tell you when I get home. \n",
            "Will: Alright, love you. \n",
            "Emma: love you too. \n",
            "\n",
            "Reference Summary:\n",
            "Emma will be home soon and she will let Will know.\n",
            "\n",
            "RL Model Summary:\n",
            "Emma will be home soon. Will will pick her up.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "Dialogue #5:\n",
            "Ollie: Hi , are you in Warsaw\n",
            "Jane: yes, just back! Btw are you free for diner the 19th?\n",
            "Ollie: nope!\n",
            "Jane: and the  18th?\n",
            "Ollie: nope, we have this party and you must be there, remember?\n",
            "Jane: oh right! i lost my calendar..  thanks for reminding me\n",
            "Ollie: we have lunch this week?\n",
            "Jane: with pleasure!\n",
            "Ollie: friday?\n",
            "Jane: ok\n",
            "Jane: what do you mean \" we don't have any more whisky!\" lol..\n",
            "Ollie: what!!!\n",
            "Jane: you just call me and the all thing i heard was that sentence about whisky... what's wrong with you?\n",
            "Ollie: oh oh... very strange! i have to be carefull may be there is some spy in my mobile! lol\n",
            "Jane: dont' worry, we'll check on friday.\n",
            "Ollie: don't forget to bring some sun with you\n",
            "Jane: I can't wait to be in Morocco..\n",
            "Ollie: enjoy and see you friday\n",
            "Jane: sorry Ollie, i'm very busy, i won't have time for lunch  tomorrow, but may be at 6pm after my courses?this trip to Morocco was so nice, but time consuming!\n",
            "Ollie: ok for tea!\n",
            "Jane: I'm on my way..\n",
            "Ollie: tea is ready, did you bring the pastries?\n",
            "Jane: I already ate them all... see you in a minute\n",
            "Ollie: ok\n",
            "\n",
            "Reference Summary:\n",
            "Jane is in Warsaw. Ollie and Jane has a party. Jane lost her calendar. They will get a lunch this week on Friday. Ollie accidentally called Jane and talked about whisky. Jane cancels lunch. They'll meet for a tea at 6 pm.\n",
            "\n",
            "RL Model Summary:\n",
            "Jane is in Warsaw. Ollie and Jane will have lunch on Friday at 6 pm.\n",
            "\n",
            "--------------------------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Evaluate RL vs Baseline\n",
        "from evaluate import load\n",
        "import pandas as pd\n",
        "import torch\n",
        "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer\n",
        "\n",
        "# Load ROUGE metric\n",
        "rouge = load(\"rouge\")\n",
        "\n",
        "# Re-load tokenizer (same one for both models)\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"/content/drive/MyDrive/rl_project/baseline_model\")\n",
        "\n",
        "def full_evaluate(model, name=\"Model\", max_samples=200):\n",
        "    preds, refs = [], []\n",
        "    model.eval()\n",
        "\n",
        "    # Use subset for speed if needed\n",
        "    num_samples = min(max_samples, len(test_ds))\n",
        "\n",
        "    for example in test_ds.select(range(num_samples)):\n",
        "        inputs = tokenizer(\n",
        "            example[\"dialogue\"],\n",
        "            return_tensors=\"pt\",\n",
        "            truncation=True,\n",
        "            max_length=512\n",
        "        ).to(model.device)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            ids = model.generate(**inputs, max_length=128, num_beams=4, early_stopping=True)\n",
        "\n",
        "        pred = tokenizer.decode(ids[0], skip_special_tokens=True)\n",
        "        preds.append(pred)\n",
        "        refs.append(example[\"summary\"])\n",
        "\n",
        "    # Compute ROUGE metrics\n",
        "    result = rouge.compute(predictions=preds, references=refs, use_stemmer=True)\n",
        "    scores = {\n",
        "        \"ROUGE-1\": round(result[\"rouge1\"], 4),\n",
        "        \"ROUGE-2\": round(result[\"rouge2\"], 4),\n",
        "        \"ROUGE-L\": round(result[\"rougeL\"], 4),\n",
        "    }\n",
        "    print(f\"\\n{name} Results:\", scores)\n",
        "    return scores\n",
        "\n",
        "\n",
        "# ✅ Load both models\n",
        "baseline_model = AutoModelForSeq2SeqLM.from_pretrained(\"/content/drive/MyDrive/rl_project/baseline_model\").to(\"cuda\")\n",
        "rl_model = AutoModelForSeq2SeqLM.from_pretrained(\"/content/drive/MyDrive/rl_project/rl_model\").to(\"cuda\")\n",
        "\n",
        "# ✅ Evaluate both\n",
        "baseline_scores = full_evaluate(baseline_model, \"Baseline\")\n",
        "rl_scores = full_evaluate(rl_model, \"RL\")\n",
        "\n",
        "# ✅ Compare results\n",
        "pd.DataFrame([baseline_scores, rl_scores], index=[\"Baseline\", \"RL\"])"
      ],
      "metadata": {
        "id": "8x38TPmFL1Ry",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 184
        },
        "outputId": "98fe50c5-ae52-401a-b21b-f16a3ef956bc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Baseline Results: {'ROUGE-1': np.float64(0.508), 'ROUGE-2': np.float64(0.2572), 'ROUGE-L': np.float64(0.4268)}\n",
            "\n",
            "RL Results: {'ROUGE-1': np.float64(0.5157), 'ROUGE-2': np.float64(0.2561), 'ROUGE-L': np.float64(0.4239)}\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "          ROUGE-1  ROUGE-2  ROUGE-L\n",
              "Baseline   0.5080   0.2572   0.4268\n",
              "RL         0.5157   0.2561   0.4239"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-4617b7e5-3c6c-4ba5-a123-01665b779b3c\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ROUGE-1</th>\n",
              "      <th>ROUGE-2</th>\n",
              "      <th>ROUGE-L</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Baseline</th>\n",
              "      <td>0.5080</td>\n",
              "      <td>0.2572</td>\n",
              "      <td>0.4268</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>RL</th>\n",
              "      <td>0.5157</td>\n",
              "      <td>0.2561</td>\n",
              "      <td>0.4239</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-4617b7e5-3c6c-4ba5-a123-01665b779b3c')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-4617b7e5-3c6c-4ba5-a123-01665b779b3c button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-4617b7e5-3c6c-4ba5-a123-01665b779b3c');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-f44c55f6-40ed-4023-8f64-f3f6e938a012\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-f44c55f6-40ed-4023-8f64-f3f6e938a012')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-f44c55f6-40ed-4023-8f64-f3f6e938a012 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"pd\",\n  \"rows\": 2,\n  \"fields\": [\n    {\n      \"column\": \"ROUGE-1\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.005444722215136444,\n        \"min\": 0.508,\n        \"max\": 0.5157,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0.5157,\n          0.508\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"ROUGE-2\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0007778174593051951,\n        \"min\": 0.2561,\n        \"max\": 0.2572,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0.2561,\n          0.2572\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"ROUGE-L\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0020506096654409976,\n        \"min\": 0.4239,\n        \"max\": 0.4268,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0.4239,\n          0.4268\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Improved RL Fine-Tuning Loop (Stable SCST)\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torch.optim import Adam\n",
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "import math\n",
        "\n",
        "# Load model from your baseline checkpoint\n",
        "model_rl = AutoModelForSeq2SeqLM.from_pretrained(\"/content/drive/MyDrive/rl_project/baseline_model\").to(\"cuda\")\n",
        "optimizer = Adam(model_rl.parameters(), lr=1e-6)\n",
        "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=200)\n",
        "\n",
        "# Reward function (already adapted for evaluate.load)\n",
        "def compute_rougeL(ref, pred):\n",
        "    return rouge.compute(predictions=[pred], references=[ref], use_stemmer=True)[\"rougeL\"]\n",
        "\n",
        "def train_rl_step(batch_dialogues, batch_refs, debug=False):\n",
        "    # Tokenize batch\n",
        "    inputs = tokenizer(\n",
        "        batch_dialogues,\n",
        "        return_tensors=\"pt\",\n",
        "        padding=True,\n",
        "        truncation=True,\n",
        "        max_length=512\n",
        "    ).to(\"cuda\")\n",
        "\n",
        "    # ====== Generate Outputs ======\n",
        "    # Greedy (baseline)\n",
        "    with torch.no_grad():\n",
        "        greedy_ids = model_rl.generate(**inputs, max_length=128)\n",
        "    greedy_txt = tokenizer.batch_decode(greedy_ids, skip_special_tokens=True)\n",
        "\n",
        "    # Sampled (exploration)\n",
        "    sampled_ids = model_rl.generate(\n",
        "        **inputs, do_sample=True, top_k=50, top_p=0.95, max_length=128\n",
        "    )\n",
        "    sampled_txt = tokenizer.batch_decode(sampled_ids, skip_special_tokens=True)\n",
        "\n",
        "    # ====== Compute Rewards ======\n",
        "    r_sampled = [compute_rougeL(r, s) for r, s in zip(batch_refs, sampled_txt)]\n",
        "    r_greedy  = [compute_rougeL(r, g) for r, g in zip(batch_refs, greedy_txt)]\n",
        "    adv = torch.tensor(np.array(r_sampled) - np.array(r_greedy), dtype=torch.float, device=\"cuda\")\n",
        "\n",
        "    # Debug print\n",
        "    if debug:\n",
        "        print(f\"Sampled ROUGE: {r_sampled}\")\n",
        "        print(f\"Greedy ROUGE:  {r_greedy}\")\n",
        "        print(f\"Advantage:     {adv.tolist()}\")\n",
        "\n",
        "    # Skip if advantage signal is flat\n",
        "    if torch.allclose(adv, torch.zeros_like(adv)):\n",
        "        return 0.0, 0.0\n",
        "\n",
        "    # ====== Compute Log Probabilities (per-sample) ======\n",
        "    labels = sampled_ids.clone()\n",
        "    labels[labels == tokenizer.pad_token_id] = -100  # ignore padding in loss\n",
        "\n",
        "    outputs = model_rl(**inputs, labels=labels, output_hidden_states=False)\n",
        "    # CrossEntropyLoss is averaged by default → recompute manually per-sample\n",
        "    logits = outputs.logits  # shape: [B, T, V]\n",
        "    shift_logits = logits[..., :-1, :].contiguous()\n",
        "    shift_labels = labels[..., 1:].contiguous()\n",
        "\n",
        "    # Get log-probs for each token\n",
        "    log_probs = F.log_softmax(shift_logits, dim=-1)\n",
        "    vocab_size = log_probs.size(-1)\n",
        "    shift_labels_flat = shift_labels.view(-1)\n",
        "    log_probs_flat = log_probs.view(-1, vocab_size)\n",
        "\n",
        "    # Gather the log-probability for the actual generated token\n",
        "    token_log_probs = log_probs_flat[torch.arange(shift_labels_flat.size(0)), shift_labels_flat]\n",
        "    token_log_probs = token_log_probs.view(shift_labels.size())\n",
        "    token_log_probs = token_log_probs.masked_fill(shift_labels == -100, 0.0)\n",
        "\n",
        "    # Sum log-probs per sequence → shape [B]\n",
        "    seq_log_probs = token_log_probs.sum(dim=1)\n",
        "\n",
        "    # ====== Compute RL Loss ======\n",
        "    adv = (adv - adv.mean()) / (adv.std() + 1e-8)  # normalize advantages\n",
        "    loss = -(adv * seq_log_probs).mean()\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    torch.nn.utils.clip_grad_norm_(model_rl.parameters(), 1.0)\n",
        "    optimizer.step()\n",
        "    scheduler.step()\n",
        "\n",
        "    return loss.item(), adv.mean().item()\n",
        "\n",
        "# ---------------------------\n",
        "# 🔁 Training Loop\n",
        "# ---------------------------\n",
        "\n",
        "num_epochs = 2       # Try 2–3 for stronger learning\n",
        "num_batches = 200    # Increase for better reward signal\n",
        "batch_size = 4\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    total_loss, total_adv = 0, 0\n",
        "    for step in tqdm(range(num_batches), desc=f\"Epoch {epoch+1}/{num_epochs}\"):\n",
        "        batch = train_df.sample(batch_size)\n",
        "        loss, adv_mean = train_rl_step(batch[\"dialogue\"].tolist(), batch[\"summary\"].tolist())\n",
        "        total_loss += loss\n",
        "        total_adv += adv_mean\n",
        "\n",
        "        if (step + 1) % 10 == 0:\n",
        "            print(f\"Step {step+1}/{num_batches} | Loss: {total_loss/(step+1):.4f} | Avg Advantage: {total_adv/(step+1):.4f}\")\n",
        "\n",
        "    print(f\"\\n✅ Epoch {epoch+1} finished | Mean Loss: {total_loss/num_batches:.4f} | Mean Advantage: {total_adv/num_batches:.4f}\\n\")\n",
        "\n",
        "# Save improved RL model\n",
        "model_rl.save_pretrained(\"/content/drive/MyDrive/rl_project/rl_model_stable\")\n",
        "tokenizer.save_pretrained(\"/content/drive/MyDrive/rl_project/rl_model_stable\")\n"
      ],
      "metadata": {
        "id": "G4j5WyUpNVjy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2256262f-5123-42ae-8aeb-01ae123c2ec6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/2:   5%|▌         | 10/200 [00:27<08:00,  2.53s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Step 10/200 | Loss: -13.5625 | Avg Advantage: 0.0000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/2:  10%|█         | 20/200 [00:51<07:04,  2.36s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Step 20/200 | Loss: -3.4108 | Avg Advantage: 0.0000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/2:  15%|█▌        | 30/200 [01:16<06:45,  2.39s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Step 30/200 | Loss: 10.5804 | Avg Advantage: 0.0000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/2:  20%|██        | 40/200 [01:42<07:09,  2.69s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Step 40/200 | Loss: 13.3723 | Avg Advantage: 0.0000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/2:  25%|██▌       | 50/200 [02:09<07:36,  3.04s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Step 50/200 | Loss: 9.5800 | Avg Advantage: -0.0000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/2:  30%|███       | 60/200 [02:39<06:35,  2.82s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Step 60/200 | Loss: 7.7796 | Avg Advantage: -0.0000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/2:  35%|███▌      | 70/200 [03:03<05:26,  2.51s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Step 70/200 | Loss: 7.5193 | Avg Advantage: -0.0000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/2:  40%|████      | 80/200 [03:30<05:26,  2.72s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Step 80/200 | Loss: 8.2833 | Avg Advantage: -0.0000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/2:  45%|████▌     | 90/200 [03:56<04:36,  2.51s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Step 90/200 | Loss: 8.4272 | Avg Advantage: -0.0000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/2:  50%|█████     | 100/200 [04:23<04:15,  2.55s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Step 100/200 | Loss: 8.6635 | Avg Advantage: 0.0000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/2:  55%|█████▌    | 110/200 [04:53<04:52,  3.25s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Step 110/200 | Loss: 9.1554 | Avg Advantage: 0.0000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/2:  60%|██████    | 120/200 [05:23<03:35,  2.70s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Step 120/200 | Loss: 6.4066 | Avg Advantage: 0.0000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/2:  65%|██████▌   | 130/200 [05:48<02:38,  2.27s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Step 130/200 | Loss: 4.1630 | Avg Advantage: 0.0000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/2:  70%|███████   | 140/200 [06:16<02:24,  2.41s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Step 140/200 | Loss: 4.1745 | Avg Advantage: 0.0000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/2:  75%|███████▌  | 150/200 [06:52<03:46,  4.52s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Step 150/200 | Loss: 6.3506 | Avg Advantage: 0.0000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/2:  80%|████████  | 160/200 [07:50<02:42,  4.07s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Step 160/200 | Loss: 5.1222 | Avg Advantage: 0.0000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/2:  85%|████████▌ | 170/200 [08:15<01:14,  2.49s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Step 170/200 | Loss: 5.6420 | Avg Advantage: 0.0000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/2:  90%|█████████ | 180/200 [08:37<00:42,  2.14s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Step 180/200 | Loss: 4.6710 | Avg Advantage: 0.0000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/2:  95%|█████████▌| 190/200 [09:03<00:25,  2.52s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Step 190/200 | Loss: 5.1996 | Avg Advantage: 0.0000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/2: 100%|██████████| 200/200 [09:34<00:00,  2.87s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Step 200/200 | Loss: 4.3602 | Avg Advantage: 0.0000\n",
            "\n",
            "✅ Epoch 1 finished | Mean Loss: 4.3602 | Mean Advantage: 0.0000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2/2:   5%|▌         | 10/200 [00:24<08:55,  2.82s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Step 10/200 | Loss: -0.4532 | Avg Advantage: -0.0000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2/2:  10%|█         | 20/200 [00:54<13:02,  4.35s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Step 20/200 | Loss: 3.4056 | Avg Advantage: -0.0000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2/2:  15%|█▌        | 30/200 [01:17<07:02,  2.49s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Step 30/200 | Loss: -3.5095 | Avg Advantage: -0.0000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2/2:  20%|██        | 40/200 [01:41<06:17,  2.36s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Step 40/200 | Loss: -2.8724 | Avg Advantage: 0.0000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2/2:  25%|██▌       | 50/200 [02:06<05:25,  2.17s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Step 50/200 | Loss: -6.2506 | Avg Advantage: 0.0000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2/2:  30%|███       | 60/200 [02:32<05:47,  2.48s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Step 60/200 | Loss: 0.3012 | Avg Advantage: -0.0000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2/2:  35%|███▌      | 70/200 [02:58<05:04,  2.34s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Step 70/200 | Loss: 4.0827 | Avg Advantage: -0.0000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2/2:  40%|████      | 80/200 [03:23<04:46,  2.38s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Step 80/200 | Loss: 4.8505 | Avg Advantage: -0.0000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2/2:  45%|████▌     | 90/200 [03:48<04:31,  2.46s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Step 90/200 | Loss: 2.9028 | Avg Advantage: -0.0000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2/2:  50%|█████     | 100/200 [04:14<04:31,  2.71s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Step 100/200 | Loss: 0.3359 | Avg Advantage: -0.0000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2/2:  55%|█████▌    | 110/200 [04:41<04:11,  2.80s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Step 110/200 | Loss: 1.4882 | Avg Advantage: -0.0000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2/2:  60%|██████    | 120/200 [05:07<03:22,  2.54s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Step 120/200 | Loss: 2.0093 | Avg Advantage: -0.0000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2/2:  65%|██████▌   | 130/200 [05:33<03:12,  2.75s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Step 130/200 | Loss: 1.7790 | Avg Advantage: -0.0000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2/2:  70%|███████   | 140/200 [06:00<02:40,  2.67s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Step 140/200 | Loss: 0.7553 | Avg Advantage: 0.0000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2/2:  75%|███████▌  | 150/200 [06:25<02:10,  2.60s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Step 150/200 | Loss: 0.1254 | Avg Advantage: 0.0000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2/2:  80%|████████  | 160/200 [06:50<01:42,  2.57s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Step 160/200 | Loss: 1.2352 | Avg Advantage: 0.0000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2/2:  85%|████████▌ | 170/200 [07:14<01:15,  2.52s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Step 170/200 | Loss: -1.1190 | Avg Advantage: 0.0000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2/2:  90%|█████████ | 180/200 [07:39<00:45,  2.28s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Step 180/200 | Loss: -1.1354 | Avg Advantage: 0.0000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2/2:  95%|█████████▌| 190/200 [08:03<00:22,  2.21s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Step 190/200 | Loss: -0.7083 | Avg Advantage: 0.0000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2/2: 100%|██████████| 200/200 [08:26<00:00,  2.53s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Step 200/200 | Loss: -0.9948 | Avg Advantage: 0.0000\n",
            "\n",
            "✅ Epoch 2 finished | Mean Loss: -0.9948 | Mean Advantage: 0.0000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('/content/drive/MyDrive/rl_project/rl_model_stable/tokenizer_config.json',\n",
              " '/content/drive/MyDrive/rl_project/rl_model_stable/special_tokens_map.json',\n",
              " '/content/drive/MyDrive/rl_project/rl_model_stable/vocab.json',\n",
              " '/content/drive/MyDrive/rl_project/rl_model_stable/merges.txt',\n",
              " '/content/drive/MyDrive/rl_project/rl_model_stable/added_tokens.json',\n",
              " '/content/drive/MyDrive/rl_project/rl_model_stable/tokenizer.json')"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_rl = AutoModelForSeq2SeqLM.from_pretrained(\"/content/drive/MyDrive/rl_project/rl_model_stable\").to(\"cuda\")\n",
        "\n",
        "rl_scores = full_evaluate(model_rl, \"RL (Stable)\", max_samples=200)\n"
      ],
      "metadata": {
        "id": "XE7zoikLU6Jy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "97285110-fc37-4f11-b0e1-a4ab8201cd93"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "RL (Stable) Results: {'ROUGE-1': np.float64(0.5053), 'ROUGE-2': np.float64(0.25), 'ROUGE-L': np.float64(0.4218)}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **TESTING**\n"
      ],
      "metadata": {
        "id": "tMNTql7ZCY8G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer\n",
        "import torch\n",
        "\n",
        "# Load your fine-tuned RL model\n",
        "model_path = \"/content/drive/MyDrive/rl_project//rl_model\"\n",
        "model_rl = AutoModelForSeq2SeqLM.from_pretrained(model_path).to(\"cuda\")\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
        "\n",
        "# 📝 Enter your own text here (can be a paragraph, article, or conversation)\n",
        "custom_text = \"\"\"\n",
        "The government has announced a new policy to encourage electric vehicle adoption.\n",
        "It includes tax incentives, charging infrastructure development, and public awareness campaigns.\n",
        "Experts believe this could accelerate the transition to sustainable transportation.\n",
        "\"\"\"\n",
        "\n",
        "# Tokenize input\n",
        "inputs = tokenizer(\n",
        "    custom_text,\n",
        "    return_tensors=\"pt\",\n",
        "    truncation=True,\n",
        "    max_length=512\n",
        ").to(\"cuda\")\n",
        "\n",
        "# Generate summary\n",
        "with torch.no_grad():\n",
        "    summary_ids = model_rl.generate(\n",
        "        **inputs,\n",
        "        max_length=128,\n",
        "        num_beams=4,         # beam search for better quality\n",
        "        early_stopping=True\n",
        "    )\n",
        "\n",
        "summary = tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
        "\n",
        "print(\"📰 Original Text:\\n\", custom_text)\n",
        "print(\"\\n💡 Generated Summary:\\n\", summary)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zbpMULy1GteZ",
        "outputId": "89a7387a-619f-4cd9-bf20-3de1ae47ea0a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "📰 Original Text:\n",
            " \n",
            "The government has announced a new policy to encourage electric vehicle adoption.\n",
            "It includes tax incentives, charging infrastructure development, and public awareness campaigns.\n",
            "Experts believe this could accelerate the transition to sustainable transportation.\n",
            "\n",
            "\n",
            "💡 Generated Summary:\n",
            " The government has announced a new policy to encourage electric vehicle adoption. It includes tax incentives, charging infrastructure development and public awareness campaigns.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(3):\n",
        "    ids = model_rl.generate(**inputs, do_sample=True, top_k=50, top_p=0.9, max_length=128)\n",
        "    print(f\"\\nSummary {i+1}:\", tokenizer.decode(ids[0], skip_special_tokens=True))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FVqC8vbOHh9i",
        "outputId": "809a4ab4-1893-4d19-fd18-98d5d118f3d0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Summary 1: The government has announced a new policy to encourage electric vehicle adoption. It includes tax incentives, charging infrastructure development, and public awareness campaigns.\n",
            "\n",
            "Summary 2: The government has announced a new policy to encourage electric vehicle adoption. It includes tax incentives, charging infrastructure development and public awareness campaigns.\n",
            "\n",
            "Summary 3: The government has announced a new policy to encourage electric vehicle adoption. It includes tax incentives, charging infrastructure development and public awareness campaigns.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer\n",
        "import torch\n",
        "\n",
        "# Load your fine-tuned RL model\n",
        "model_path = \"/content/drive/MyDrive/rl_project/rl_model\"\n",
        "model_rl = AutoModelForSeq2SeqLM.from_pretrained(model_path).to(\"cuda\")\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
        "\n",
        "# 📝 Enter your own text here (can be a paragraph, article, or conversation)\n",
        "custom_text = \"\"\"\n",
        "Raj had the most exciting summer holidays this year.\n",
        " He traveled to Andhra Pradesh with his family, eager to explore new places. Their first stop was Visakhapatnam,\n",
        "  where Raj loved visiting the beaches and trying water sports.\n",
        "  He was fascinated by the serene beauty of Araku Valley and spent hours capturing its lush landscapes.\n",
        "   At Borra Caves, he was amazed by the stalactites and stalagmites.\n",
        "   Raj also enjoyed tasting the local Andhra cuisine, especially spicy biryani and Andhra sweets.\n",
        "    He visited historic temples in Vijayawada, soaking in the culture and architecture.\n",
        "    Riding through the hills and valleys, he felt a sense of adventure every day.\n",
        "     Evenings were spent enjoying local festivals and interacting with friendly locals.\n",
        "     By the end of his trip, Raj felt happy and refreshed, cherishing memories that would last a lifetime.\n",
        "\"\"\"\n",
        "\n",
        "# Tokenize input\n",
        "inputs = tokenizer(\n",
        "    custom_text,\n",
        "    return_tensors=\"pt\",\n",
        "    truncation=True,\n",
        "    max_length=512\n",
        ").to(\"cuda\")\n",
        "\n",
        "# Generate summary\n",
        "with torch.no_grad():\n",
        "    summary_ids = model_rl.generate(\n",
        "        **inputs,\n",
        "        max_length=128,\n",
        "        num_beams=4,         # beam search for better quality\n",
        "        early_stopping=True\n",
        "    )\n",
        "\n",
        "summary = tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
        "\n",
        "print(\"📰 Original Text:\\n\", custom_text)\n",
        "print(\"\\n💡 Generated Summary:\\n\", summary)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pQ3K8VguLO4k",
        "outputId": "edc234a0-bb56-4b53-980d-3461cf750f7c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "📰 Original Text:\n",
            " \n",
            "Raj had the most exciting summer holidays this year.\n",
            " He traveled to Andhra Pradesh with his family, eager to explore new places. Their first stop was Visakhapatnam,\n",
            "  where Raj loved visiting the beaches and trying water sports. \n",
            "  He was fascinated by the serene beauty of Araku Valley and spent hours capturing its lush landscapes.\n",
            "   At Borra Caves, he was amazed by the stalactites and stalagmites. \n",
            "   Raj also enjoyed tasting the local Andhra cuisine, especially spicy biryani and Andhra sweets.\n",
            "    He visited historic temples in Vijayawada, soaking in the culture and architecture.\n",
            "    Riding through the hills and valleys, he felt a sense of adventure every day.\n",
            "     Evenings were spent enjoying local festivals and interacting with friendly locals. \n",
            "     By the end of his trip, Raj felt happy and refreshed, cherishing memories that would last a lifetime.\n",
            "\n",
            "\n",
            "💡 Generated Summary:\n",
            " Raj spent summer holidays in Andhra Pradesh with his family. His first stop was Visakhapatnam, where he enjoyed visiting the beaches and trying water sports. He also spent time in Araku Valley and Borra Caves.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(3):\n",
        "    ids = model_rl.generate(**inputs, do_sample=True, top_k=50, top_p=0.9, max_length=128)\n",
        "    print(f\"\\nSummary {i+1}:\", tokenizer.decode(ids[0], skip_special_tokens=True))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QHAjLFHmNRcg",
        "outputId": "6c802926-b323-41cd-978f-7103322f2be9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Summary 1: Raj travelled to Andhra Pradesh with his family, eager to explore new places. His first stop was Visakhapatnam, where he loved visiting the beaches and trying water sports.\n",
            "\n",
            "Summary 2: Raj travelled to Andhra Pradesh with his family, eager to explore new places. His first stop was Visakhapatnam, where he enjoyed visiting the beaches and trying water sports. He spent a lot of time in the mountains and valleys.\n",
            "\n",
            "Summary 3: Raj spent summer holidays in Andhra Pradesh with his family. His first stop was Visakhapatnam, where he enjoyed visiting the beaches and trying water sports. He also spent time at Borra Caves.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer\n",
        "import torch\n",
        "\n",
        "# Load your fine-tuned RL model\n",
        "model_path = \"/content/drive/MyDrive/rl_project/rl_model\"\n",
        "model_rl = AutoModelForSeq2SeqLM.from_pretrained(model_path).to(\"cuda\")\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
        "\n",
        "# 📝 Enter your own text here (can be a paragraph, article, or conversation)\n",
        "custom_text = \"\"\"\n",
        "Dear Team,\n",
        "I hope this email finds you well.\n",
        " As discussed in yesterday’s meeting, we need to finalize the project proposal by Friday.\n",
        " Please ensure that all sections are updated, especially the financial estimates and timeline.\n",
        " Also, share the draft with me by Thursday for review.\n",
        "Regards,\n",
        "Manager\n",
        "\"\"\"\n",
        "def generate_summary(model, tokenizer, text, device=\"cuda\"):\n",
        "    inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, max_length=512).to(device)\n",
        "    ids = model.generate(\n",
        "        **inputs,\n",
        "        num_beams=6,               # try 4,6,8\n",
        "        length_penalty=1.0,        # 0.6..1.2 (higher favours longer summaries)\n",
        "        max_length=128,\n",
        "        no_repeat_ngram_size=3,    # prevents repetition\n",
        "        early_stopping=True,\n",
        "        num_return_sequences=1\n",
        "    )\n",
        "    return tokenizer.decode(ids[0], skip_special_tokens=True)\n",
        "\n",
        "# Tokenize input\n",
        "inputs = tokenizer(\n",
        "    custom_text,\n",
        "    return_tensors=\"pt\",\n",
        "    truncation=True,\n",
        "    max_length=512\n",
        ").to(\"cuda\")\n",
        "\n",
        "# Generate summary\n",
        "with torch.no_grad():\n",
        "    summary_ids = model_rl.generate(\n",
        "        **inputs,\n",
        "        max_length=512,\n",
        "        num_beams=4,         # beam search for better quality\n",
        "        early_stopping=True\n",
        "    )\n",
        "\n",
        "summary = tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
        "\n",
        "print(\"📰 Original Text:\\n\", custom_text)\n",
        "print(\"\\n💡 Generated Summary:\\n\", summary)"
      ],
      "metadata": {
        "id": "b4vy5-GiO3xM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5639a57c-750d-4f3a-afc2-3eeb031d59d3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "📰 Original Text:\n",
            " \n",
            "Dear Team,\n",
            "I hope this email finds you well.\n",
            " As discussed in yesterday’s meeting, we need to finalize the project proposal by Friday. \n",
            " Please ensure that all sections are updated, especially the financial estimates and timeline. \n",
            " Also, share the draft with me by Thursday for review.\n",
            "Regards,\n",
            "Manager\n",
            "\n",
            "\n",
            "💡 Generated Summary:\n",
            " As discussed in yesterday's meeting, they need to finalize the project proposal by Friday.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "As discussed in yesterday's meeting, they need to finalize the project proposal by Friday."
      ],
      "metadata": {
        "id": "LgbFy6pudfVa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer\n",
        "import torch\n",
        "\n",
        "# Load your fine-tuned RL model\n",
        "model_path = \"/content/drive/MyDrive/rl_project/rl_model\"\n",
        "model_rl = AutoModelForSeq2SeqLM.from_pretrained(model_path).to(\"cuda\")\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
        "\n",
        "# 📝 Enter your own text here (can be a paragraph, article, or conversation)\n",
        "custom_text = \"\"\"\n",
        "Dear Students,\n",
        "As part of your coursework, you are required to submit a project report.\n",
        "The report should be 15 pages minimum, with proper references. Please form groups of 4–5.\n",
        "The submission deadline is 20th October. Late submissions will not be accepted.\n",
        "We will also have a viva on 25th October. Kindly ensure originality to avoid plagiarism issues.\n",
        "\"\"\"\n",
        "\n",
        "# Tokenize input\n",
        "inputs = tokenizer(\n",
        "    custom_text,\n",
        "    return_tensors=\"pt\",\n",
        "    truncation=True,\n",
        "    max_length=512\n",
        ").to(\"cuda\")\n",
        "\n",
        "# Generate summary\n",
        "'''with torch.no_grad():\n",
        "    summary_ids = model_rl.generate(\n",
        "        **inputs,\n",
        "        max_length=120,\n",
        "        min_length=40,\n",
        "        num_beams=10,         # beam search for better quality\n",
        "        early_stopping=True\n",
        "    )'''\n",
        "\n",
        "\n",
        "\n",
        "summary_ids = model_rl.generate(\n",
        "    **inputs,\n",
        "    max_length=120,\n",
        "    min_length=30,\n",
        "    num_beams=4,\n",
        "    temperature=0.9,\n",
        "    top_k=50,\n",
        "    top_p=0.95,\n",
        "    do_sample=True,\n",
        "    early_stopping=True\n",
        ")\n",
        "summary = tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
        "\n",
        "print(\"📰 Original Text:\\n\", custom_text.strip())\n",
        "print(\"\\n💡 Generated Summary:\\n\", summary)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q3gVFYr5a9aJ",
        "outputId": "593ad20b-0b12-461d-82be-322ca1869fdb"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "📰 Original Text:\n",
            " Dear Students,\n",
            "As part of your coursework, you are required to submit a project report.\n",
            "The report should be 15 pages minimum, with proper references. Please form groups of 4–5.\n",
            "The submission deadline is 20th October. Late submissions will not be accepted.\n",
            "We will also have a viva on 25th October. Kindly ensure originality to avoid plagiarism issues.\n",
            "\n",
            "💡 Generated Summary:\n",
            " As part of your coursework, you are required to submit a project report. The deadline is 20th October. The viva on 25th October is also required.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install flask flask-ngrok\n"
      ],
      "metadata": {
        "id": "Ny7Qd8suoFlS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9e6eaa8c-fb14-40de-d9b4-9448b3515d81"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ERROR:root:Unexpected exception finding object shape\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/google/colab/_debugpy_repr.py\", line 54, in get_shape\n",
            "    shape = getattr(obj, 'shape', None)\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/werkzeug/local.py\", line 318, in __get__\n",
            "    obj = instance._get_current_object()\n",
            "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/werkzeug/local.py\", line 519, in _get_current_object\n",
            "    raise RuntimeError(unbound_message) from None\n",
            "RuntimeError: Working outside of request context.\n",
            "\n",
            "This typically means that you attempted to use functionality that needed\n",
            "an active HTTP request. Consult the documentation on testing for\n",
            "information about how to avoid this problem.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: flask in /usr/local/lib/python3.12/dist-packages (3.1.2)\n",
            "Collecting flask-ngrok\n",
            "  Downloading flask_ngrok-0.0.25-py3-none-any.whl.metadata (1.8 kB)\n",
            "Requirement already satisfied: blinker>=1.9.0 in /usr/local/lib/python3.12/dist-packages (from flask) (1.9.0)\n",
            "Requirement already satisfied: click>=8.1.3 in /usr/local/lib/python3.12/dist-packages (from flask) (8.3.0)\n",
            "Requirement already satisfied: itsdangerous>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from flask) (2.2.0)\n",
            "Requirement already satisfied: jinja2>=3.1.2 in /usr/local/lib/python3.12/dist-packages (from flask) (3.1.6)\n",
            "Requirement already satisfied: markupsafe>=2.1.1 in /usr/local/lib/python3.12/dist-packages (from flask) (3.0.3)\n",
            "Requirement already satisfied: werkzeug>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from flask) (3.1.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from flask-ngrok) (2.32.4)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->flask-ngrok) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->flask-ngrok) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->flask-ngrok) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->flask-ngrok) (2025.10.5)\n",
            "Downloading flask_ngrok-0.0.25-py3-none-any.whl (3.1 kB)\n",
            "Installing collected packages: flask-ngrok\n",
            "Successfully installed flask-ngrok-0.0.25\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from flask import Flask, request, jsonify\n",
        "from flask_ngrok import run_with_ngrok\n",
        "from transformers import pipeline\n",
        "\n",
        "summarizer = pipeline(\"summarization\", model=\"/content/drive/MyDrive/rl_project/rl_model\")\n",
        "\n",
        "app = Flask(__name__)\n",
        "run_with_ngrok(app)  # Enables public access to your Colab Flask app\n",
        "\n",
        "@app.route('/summarize', methods=['POST'])\n",
        "def summarize():\n",
        "    data = request.get_json()\n",
        "    text = data['text']\n",
        "    result = summarizer(text, max_length=150, min_length=40, do_sample=False)\n",
        "    return jsonify({'summary': result[0]['summary_text']})\n",
        "\n",
        "app.run()"
      ],
      "metadata": {
        "id": "9vv7O-Zaj-nN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4dbfe040-3d62-4b75-a81f-9a600ca7b62c"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cuda:0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " * Serving Flask app '__main__'\n",
            " * Debug mode: off\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:werkzeug:\u001b[31m\u001b[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\u001b[0m\n",
            " * Running on http://127.0.0.1:5000\n",
            "INFO:werkzeug:\u001b[33mPress CTRL+C to quit\u001b[0m\n",
            "Exception in thread Thread-4:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/urllib3/connection.py\", line 198, in _new_conn\n",
            "    sock = connection.create_connection(\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/urllib3/util/connection.py\", line 85, in create_connection\n",
            "    raise err\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/urllib3/util/connection.py\", line 73, in create_connection\n",
            "    sock.connect(sa)\n",
            "ConnectionRefusedError: [Errno 111] Connection refused\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/urllib3/connectionpool.py\", line 787, in urlopen\n",
            "    response = self._make_request(\n",
            "               ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/urllib3/connectionpool.py\", line 493, in _make_request\n",
            "    conn.request(\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/urllib3/connection.py\", line 494, in request\n",
            "    self.endheaders()\n",
            "  File \"/usr/lib/python3.12/http/client.py\", line 1333, in endheaders\n",
            "    self._send_output(message_body, encode_chunked=encode_chunked)\n",
            "  File \"/usr/lib/python3.12/http/client.py\", line 1093, in _send_output\n",
            "    self.send(msg)\n",
            "  File \"/usr/lib/python3.12/http/client.py\", line 1037, in send\n",
            "    self.connect()\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/urllib3/connection.py\", line 325, in connect\n",
            "    self.sock = self._new_conn()\n",
            "                ^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/urllib3/connection.py\", line 213, in _new_conn\n",
            "    raise NewConnectionError(\n",
            "urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x7a78f9c73740>: Failed to establish a new connection: [Errno 111] Connection refused\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/requests/adapters.py\", line 667, in send\n",
            "    resp = conn.urlopen(\n",
            "           ^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/urllib3/connectionpool.py\", line 841, in urlopen\n",
            "    retries = retries.increment(\n",
            "              ^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/urllib3/util/retry.py\", line 519, in increment\n",
            "    raise MaxRetryError(_pool, url, reason) from reason  # type: ignore[arg-type]\n",
            "    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='localhost', port=4040): Max retries exceeded with url: /api/tunnels (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7a78f9c73740>: Failed to establish a new connection: [Errno 111] Connection refused'))\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.12/threading.py\", line 1075, in _bootstrap_inner\n",
            "    self.run()\n",
            "  File \"/usr/lib/python3.12/threading.py\", line 1433, in run\n",
            "    self.function(*self.args, **self.kwargs)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/flask_ngrok.py\", line 70, in start_ngrok\n",
            "    ngrok_address = _run_ngrok()\n",
            "                    ^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/flask_ngrok.py\", line 35, in _run_ngrok\n",
            "    tunnel_url = requests.get(localhost_url).text  # Get the tunnel information\n",
            "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/requests/api.py\", line 73, in get\n",
            "    return request(\"get\", url, params=params, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/requests/api.py\", line 59, in request\n",
            "    return session.request(method=method, url=url, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/requests/sessions.py\", line 589, in request\n",
            "    resp = self.send(prep, **send_kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/requests/sessions.py\", line 703, in send\n",
            "    r = adapter.send(request, **kwargs)\n",
            "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/requests/adapters.py\", line 700, in send\n",
            "    raise ConnectionError(e, request=request)\n",
            "requests.exceptions.ConnectionError: HTTPConnectionPool(host='localhost', port=4040): Max retries exceeded with url: /api/tunnels (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7a78f9c73740>: Failed to establish a new connection: [Errno 111] Connection refused'))\n",
            "ERROR:root:Unexpected exception finding object shape\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/google/colab/_debugpy_repr.py\", line 54, in get_shape\n",
            "    shape = getattr(obj, 'shape', None)\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/werkzeug/local.py\", line 318, in __get__\n",
            "    obj = instance._get_current_object()\n",
            "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/werkzeug/local.py\", line 519, in _get_current_object\n",
            "    raise RuntimeError(unbound_message) from None\n",
            "RuntimeError: Working outside of request context.\n",
            "\n",
            "This typically means that you attempted to use functionality that needed\n",
            "an active HTTP request. Consult the documentation on testing for\n",
            "information about how to avoid this problem.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install flask pyngrok\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2MucEuBFCQSa",
        "outputId": "dafbcbf2-03ff-4e34-850c-d27001837d5a"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: flask in /usr/local/lib/python3.12/dist-packages (3.1.2)\n",
            "Collecting pyngrok\n",
            "  Downloading pyngrok-7.4.1-py3-none-any.whl.metadata (8.1 kB)\n",
            "Requirement already satisfied: blinker>=1.9.0 in /usr/local/lib/python3.12/dist-packages (from flask) (1.9.0)\n",
            "Requirement already satisfied: click>=8.1.3 in /usr/local/lib/python3.12/dist-packages (from flask) (8.3.0)\n",
            "Requirement already satisfied: itsdangerous>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from flask) (2.2.0)\n",
            "Requirement already satisfied: jinja2>=3.1.2 in /usr/local/lib/python3.12/dist-packages (from flask) (3.1.6)\n",
            "Requirement already satisfied: markupsafe>=2.1.1 in /usr/local/lib/python3.12/dist-packages (from flask) (3.0.3)\n",
            "Requirement already satisfied: werkzeug>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from flask) (3.1.3)\n",
            "Requirement already satisfied: PyYAML>=5.1 in /usr/local/lib/python3.12/dist-packages (from pyngrok) (6.0.3)\n",
            "Downloading pyngrok-7.4.1-py3-none-any.whl (25 kB)\n",
            "Installing collected packages: pyngrok\n",
            "Successfully installed pyngrok-7.4.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install flask pyngrok transformers torch\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cxzRwoU_FBlt",
        "outputId": "b6f41aa1-31e3-4394-900d-834f696344d4"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: flask in /usr/local/lib/python3.12/dist-packages (3.1.2)\n",
            "Collecting pyngrok\n",
            "  Downloading pyngrok-7.4.1-py3-none-any.whl.metadata (8.1 kB)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.12/dist-packages (4.57.1)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (2.8.0+cu126)\n",
            "Requirement already satisfied: blinker>=1.9.0 in /usr/local/lib/python3.12/dist-packages (from flask) (1.9.0)\n",
            "Requirement already satisfied: click>=8.1.3 in /usr/local/lib/python3.12/dist-packages (from flask) (8.3.0)\n",
            "Requirement already satisfied: itsdangerous>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from flask) (2.2.0)\n",
            "Requirement already satisfied: jinja2>=3.1.2 in /usr/local/lib/python3.12/dist-packages (from flask) (3.1.6)\n",
            "Requirement already satisfied: markupsafe>=2.1.1 in /usr/local/lib/python3.12/dist-packages (from flask) (3.0.3)\n",
            "Requirement already satisfied: werkzeug>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from flask) (3.1.3)\n",
            "Requirement already satisfied: PyYAML>=5.1 in /usr/local/lib/python3.12/dist-packages (from pyngrok) (6.0.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from transformers) (3.20.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.35.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (25.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from transformers) (2.32.4)\n",
            "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.22.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.6.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.12/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch) (3.5)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch) (3.4.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (1.1.10)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2025.10.5)\n",
            "Downloading pyngrok-7.4.1-py3-none-any.whl (25 kB)\n",
            "Installing collected packages: pyngrok\n",
            "Successfully installed pyngrok-7.4.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyngrok import ngrok\n",
        "from flask import Flask, request, jsonify\n",
        "from transformers import pipeline\n",
        "\n",
        "# Set your ngrok auth token\n",
        "ngrok.set_auth_token(\"34aheODnO9cGcWMVfFdO3vd9FzG_7NWadUxb8hLqhPchdgxXt\")\n"
      ],
      "metadata": {
        "id": "t2phzAHaFC_a"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create Flask app\n",
        "app = Flask(__name__)\n",
        "\n",
        "# Load summarization model\n",
        "summarizer = pipeline(\"summarization\", model=\"/content/drive/MyDrive/rl_project/rl_model\")\n",
        "\n",
        "@app.route('/')\n",
        "def home():\n",
        "    return \"<h2>Text Summarization API is running!</h2><p>Use POST /summarize with JSON {'text': 'your text here'}</p>\"\n",
        "\n",
        "@app.route('/summarize', methods=['POST'])\n",
        "def summarize():\n",
        "    data = request.get_json()\n",
        "    text = data.get('text', '')\n",
        "    if not text.strip():\n",
        "        return jsonify({'error': 'No input text provided'}), 400\n",
        "    summary = summarizer(text, max_length=150, min_length=40, do_sample=False)[0]['summary_text']\n",
        "    return jsonify({'summary': summary})\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ABqwzzGwFPFQ",
        "outputId": "88b5a155-dbc9-474f-fd4e-f75d40f017bc"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cuda:0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Open ngrok tunnel on port 5000\n",
        "public_url = ngrok.connect(5000).public_url\n",
        "print(f\"Your public app URL: {public_url}\")\n",
        "\n",
        "# Run Flask app\n",
        "app.run(port=5000)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2lZ1HZ6ZFZHM",
        "outputId": "e3a11480-972f-4c3a-f27e-9a7e6bd6258c"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Your public app URL: https://nery-unintoned-gloomily.ngrok-free.dev\n",
            " * Serving Flask app '__main__'\n",
            " * Debug mode: off\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:werkzeug:\u001b[31m\u001b[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\u001b[0m\n",
            " * Running on http://127.0.0.1:5000\n",
            "INFO:werkzeug:\u001b[33mPress CTRL+C to quit\u001b[0m\n",
            "WARNING:pyngrok.process.ngrok:t=2025-10-26T05:55:07+0000 lvl=warn msg=\"failed to check for update\" obj=updater err=\"Post \\\"https://update.equinox.io/check\\\": context deadline exceeded\"\n",
            "INFO:werkzeug:127.0.0.1 - - [26/Oct/2025 05:55:27] \"GET / HTTP/1.1\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [26/Oct/2025 05:55:27] \"\u001b[33mGET /favicon.ico HTTP/1.1\u001b[0m\" 404 -\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyngrok import ngrok\n",
        "from flask import Flask, request, jsonify, render_template\n",
        "from transformers import pipeline\n",
        "import os\n",
        "\n",
        "# Authenticate with ngrok\n",
        "ngrok.set_auth_token(\"34aheODnO9cGcWMVfFdO3vd9FzG_7NWadUxb8hLqhPchdgxXt\")\n",
        "\n",
        "# Create Flask app\n",
        "app = Flask(__name__)\n",
        "\n",
        "# Load summarization model\n",
        "summarizer = pipeline(\"summarization\", model=\"/content/drive/MyDrive/rl_project/rl_model\")\n",
        "\n",
        "@app.route('/')\n",
        "def home():\n",
        "    return render_template(\"index.html\")\n",
        "\n",
        "@app.route('/summarize', methods=['POST'])\n",
        "def summarize():\n",
        "    data = request.get_json() or {}\n",
        "    text = data.get('text', \"\")\n",
        "    if not text.strip():\n",
        "        return jsonify({\"error\": \"No text provided\"}), 400\n",
        "\n",
        "    summary = summarizer(text, max_length=150, min_length=40, do_sample=False)\n",
        "    return jsonify({\"summary\": summary[0]['summary_text']})\n",
        "\n",
        "# Create folders for templates if not present\n",
        "os.makedirs(\"templates\", exist_ok=True)\n",
        "\n",
        "# Save HTML frontend file\n",
        "html_code = '''<!DOCTYPE html>\n",
        "<html lang=\"en\">\n",
        "<head>\n",
        "  <meta charset=\"UTF-8\">\n",
        "  <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\">\n",
        "  <title>AI Text Summarizer</title>\n",
        "\n",
        "  <!-- Google Fonts -->\n",
        "  <link href=\"https://fonts.googleapis.com/css2?family=Poppins:wght@400;600&family=Inter:wght@400;500;700&display=swap\" rel=\"stylesheet\">\n",
        "\n",
        "  <!-- Styling -->\n",
        "  <style>\n",
        "    body {\n",
        "      margin: 0;\n",
        "      font-family: 'Poppins', sans-serif;\n",
        "      background: linear-gradient(135deg, #e1f5fe, #f3e5f5);\n",
        "      color: #333;\n",
        "    }\n",
        "\n",
        "    header {\n",
        "      text-align: center;\n",
        "      padding: 40px 20px;\n",
        "      background: rgba(255, 255, 255, 0.6);\n",
        "      backdrop-filter: blur(10px);\n",
        "      box-shadow: 0 2px 8px rgba(0, 0, 0, 0.1);\n",
        "      border-bottom: 1px solid rgba(0, 0, 0, 0.1);\n",
        "    }\n",
        "\n",
        "    header h1 {\n",
        "      margin: 0;\n",
        "      font-weight: 700;\n",
        "      font-size: 2rem;\n",
        "      color: #3f51b5;\n",
        "    }\n",
        "\n",
        "    header p {\n",
        "      margin-top: 8px;\n",
        "      color: #555;\n",
        "      font-size: 1rem;\n",
        "    }\n",
        "\n",
        "    main {\n",
        "      max-width: 800px;\n",
        "      margin: 50px auto;\n",
        "      background: #fff;\n",
        "      padding: 40px;\n",
        "      border-radius: 10px;\n",
        "      box-shadow: 0 4px 20px rgba(0, 0, 0, 0.1);\n",
        "    }\n",
        "\n",
        "    textarea {\n",
        "      width: 100%;\n",
        "      height: 200px;\n",
        "      padding: 15px;\n",
        "      font-size: 1rem;\n",
        "      border: 1px solid #ccc;\n",
        "      border-radius: 8px;\n",
        "      outline: none;\n",
        "      resize: none;\n",
        "      transition: border-color 0.3s;\n",
        "    }\n",
        "\n",
        "    textarea:focus {\n",
        "      border-color: #3f51b5;\n",
        "    }\n",
        "\n",
        "    button {\n",
        "      margin-top: 20px;\n",
        "      padding: 12px 30px;\n",
        "      font-size: 1rem;\n",
        "      font-weight: 500;\n",
        "      color: white;\n",
        "      background: linear-gradient(90deg, #3f51b5, #5c6bc0);\n",
        "      border: none;\n",
        "      border-radius: 8px;\n",
        "      cursor: pointer;\n",
        "      transition: transform 0.2s, background 0.3s;\n",
        "    }\n",
        "\n",
        "    button:hover {\n",
        "      transform: translateY(-2px);\n",
        "      background: linear-gradient(90deg, #303f9f, #3949ab);\n",
        "    }\n",
        "\n",
        "    .result-box {\n",
        "      margin-top: 30px;\n",
        "      background: #f7f9fc;\n",
        "      border-left: 5px solid #3f51b5;\n",
        "      padding: 20px;\n",
        "      border-radius: 8px;\n",
        "      min-height: 100px;\n",
        "    }\n",
        "\n",
        "    footer {\n",
        "      text-align: center;\n",
        "      margin-top: 40px;\n",
        "      padding: 20px;\n",
        "      color: #666;\n",
        "      font-size: 0.9rem;\n",
        "    }\n",
        "\n",
        "    @media (max-width: 600px) {\n",
        "      main {\n",
        "        padding: 25px;\n",
        "        margin: 20px;\n",
        "      }\n",
        "\n",
        "      textarea {\n",
        "        height: 150px;\n",
        "      }\n",
        "    }\n",
        "  </style>\n",
        "</head>\n",
        "\n",
        "<body>\n",
        "  <header>\n",
        "    <h1>AI Text Summarizer</h1>\n",
        "    <p>Generate concise summaries using advanced NLP models</p>\n",
        "  </header>\n",
        "\n",
        "  <main>\n",
        "    <label for=\"inputText\"><strong>Enter your text to summarize:</strong></label>\n",
        "    <textarea id=\"inputText\" placeholder=\"Paste or type your paragraph here...\"></textarea>\n",
        "    <button onclick=\"summarize()\">Summarize</button>\n",
        "\n",
        "    <div class=\"result-box\" id=\"outputText\">\n",
        "      <em>Summary will appear here...</em>\n",
        "    </div>\n",
        "  </main>\n",
        "\n",
        "  <footer>\n",
        "    © 2025 AI Summarization App | Powered by Flask & Hugging Face Transformers\n",
        "  </footer>\n",
        "\n",
        "  <script>\n",
        "    async function summarize() {\n",
        "      const text = document.getElementById('inputText').value.trim();\n",
        "      const output = document.getElementById('outputText');\n",
        "      if (!text) {\n",
        "        output.innerHTML = \"<em style='color:red;'>Please enter some text first!</em>\";\n",
        "        return;\n",
        "      }\n",
        "      output.innerHTML = \"<em>Summarizing, please wait...</em>\";\n",
        "      try {\n",
        "        const res = await fetch('/summarize', {\n",
        "          method: 'POST',\n",
        "          headers: {'Content-Type': 'application/json'},\n",
        "          body: JSON.stringify({ text: text })\n",
        "        });\n",
        "        const data = await res.json();\n",
        "        if (data.summary) {\n",
        "          output.innerHTML = `<strong>Summary:</strong><br>${data.summary}`;\n",
        "        } else {\n",
        "          output.innerHTML = `<em style='color:red;'>Error: ${data.error || \"Unexpected issue occurred.\"}</em>`;\n",
        "        }\n",
        "      } catch (error) {\n",
        "        output.innerHTML = `<em style='color:red;'>Server Error: Unable to connect.</em>`;\n",
        "      }\n",
        "    }\n",
        "  </script>\n",
        "</body>\n",
        "</html>\n",
        "\n",
        "'''\n",
        "with open(\"templates/index.html\", \"w\") as f:\n",
        "    f.write(html_code)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zFlGRO8ZGhdr",
        "outputId": "6a8b60e4-e233-41ee-ce02-98adba28d8da"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cuda:0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Connect to ngrok and run Flask\n",
        "public_url = ngrok.connect(5000).public_url\n",
        "print(f\"Public URL: {public_url}\")\n",
        "app.run(port=5000)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JzuoFysGHAft",
        "outputId": "fc6b1a60-90f7-4fa6-953b-3025affb2ccc"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Public URL: https://nery-unintoned-gloomily.ngrok-free.dev\n",
            " * Serving Flask app '__main__'\n",
            " * Debug mode: off\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:werkzeug:\u001b[31m\u001b[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\u001b[0m\n",
            " * Running on http://127.0.0.1:5000\n",
            "INFO:werkzeug:\u001b[33mPress CTRL+C to quit\u001b[0m\n",
            "INFO:werkzeug:127.0.0.1 - - [26/Oct/2025 10:04:21] \"GET / HTTP/1.1\" 200 -\n",
            "Your max_length is set to 150, but your input_length is only 113. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=56)\n",
            "Both `max_new_tokens` (=256) and `max_length`(=150) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "INFO:werkzeug:127.0.0.1 - - [26/Oct/2025 10:06:30] \"POST /summarize HTTP/1.1\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [26/Oct/2025 10:06:35] \"GET / HTTP/1.1\" 200 -\n",
            "Your max_length is set to 150, but your input_length is only 113. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=56)\n",
            "Both `max_new_tokens` (=256) and `max_length`(=150) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "INFO:werkzeug:127.0.0.1 - - [26/Oct/2025 10:06:39] \"POST /summarize HTTP/1.1\" 200 -\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "y8UvZhkUHE1d"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}